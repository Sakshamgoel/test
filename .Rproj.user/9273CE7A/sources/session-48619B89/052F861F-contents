get_initial_beta <- function(y, X)
{
    solve(t(X) %*% X) %*% t(X) %*% y
}

logistic_regression <- function(beta, y, X)
{
    p <- 1 / (1 + exp(-X %*% beta))
    sum(-((1 - y) * log(1 - p)) - (y * log(p)))
}

get_beta_estimate <- function(response, predictors)
{
    initial_beta <- get_initial_beta(response, predictors)
    beta_est <- optim(get_initial_beta(response, predictors),
                      logistic_regression,
                      y = response,
                      X = predictors)$par
    
    output <- list("initial_beta" = initial_beta,
                   "beta_estimate" = beta_est,
                   "response" = response,
                   "predictors" = predictors)
    class(output) <- "logistic_regression"

    return(output)
}

get_beta_confidence_intervals <- function(response, predictors, alpha, replications = 20)
{
    beta_mean <- matrix(NA, ncol = ncol(predictors), nrow = replications)
    
    sample_X <- cbind(response, predictors)
    
    for(i in 1:replications)
    {
        new_sample <- sample_X[sample(1:nrow(sample_X), replace = TRUE), ]
        
        beta_mean[i,] <- get_beta_estimate(response = new_sample[ ,1],
                                           predictors = new_sample[,2:ncol(new_sample)])$beta_estimate
    }
    
    cat("Bootstrap Confidence Intervals with alpha =",
                      alpha, "and replications =", replications, ":\n")
    
    for(i in 1:ncol(beta_mean))
    {
        cat("Variable:", i, "\n")
        print(quantile(beta_mean[,i], c(alpha, 1 - alpha)))
    }
}

get_confusion_matrix <- function(lr_result, cut_off = 0.5)
{
    p <- 1 / (1 + exp(-lr_result$predictors %*% lr_result$beta_estimate))
    predicted_response <- ifelse(p > cut_off, 1, 0)
    
    tn <- sum((lr_result$response == 0) & (predicted_response == 0))
    fp <- sum((lr_result$response == 0) & (predicted_response == 1))
    fn <- sum((lr_result$response == 1) & (predicted_response == 0))
    tp <- sum((lr_result$response == 1) & (predicted_response == 1))
    
    total <- tp + tn + fp + fn
    
    confusion_matrix <- list("tp" = tp,
                             "tn" = tn,
                             "fp" = fp,
                             "fn" = fn,
                             "total" = total)
    
    return(confusion_matrix)
}

get_prevalence <- function(lr_result, cut_off = 0.5)
{
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
    prevalence <- (confusion_matrix$fn + confusion_matrix$tp) / confusion_matrix$total

    return(prevalence)
}

get_accuracy <- function(lr_result, cut_off = 0.5)
{
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
    accuracy <- (confusion_matrix$tp + confusion_matrix$tn) / confusion_matrix$total
    
    return(accuracy)
}

get_sensitivity <- function(lr_result, cut_off = 0.5)
{
    
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
    sensitivity <- confusion_matrix$tp / (confusion_matrix$tp + confusion_matrix$fn)
    
    return(sensitivity)
}

get_specificity <- function(lr_result, cut_off = 0.5)
{
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
    specificity <- confusion_matrix$tn / (confusion_matrix$tn + confusion_matrix$fp)
    
    return(specificity)
}

get_false_discovery_ratio <- function(lr_result, cut_off = 0.5)
{
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
    fdr <- confusion_matrix$fp / (confusion_matrix$fp + confusion_matrix$tp)
    
    return(fdr)
}

get_diagnostic_odds_ratio <- function(lr_result, cut_off = 0.5)
{
    confusion_matrix <- get_confusion_matrix(lr_result, cut_off)
        
    fpr <- confusion_matrix$fp / (confusion_matrix$fp + confusion_matrix$tn)
    fnr <- confusion_matrix$fn / (confusion_matrix$fn + confusion_matrix$tp)
        
    sensitivity <- get_sensitivity(lr_result, cut_off)
    specificity <- get_specificity(lr_result, cut_off)
    
    dor <- (sensitivity / fpr) / (fnr / specificity)
    
    return(dor)
}

plot_confusion_matrix <- function(lr_result, cut_off = 0.5)
{
    cm <- get_confusion_matrix(lr_result, cut_off)
    
    Target <- factor(c(0, 0, 1, 1))
    Prediction <- factor(c(0, 1, 0, 1))
    values <- c(cm$tn, cm$fp, cm$fn, cm$tp)
    df <- data.frame(Target, Prediction, values)
    
    plot <- ggplot(data =  df, mapping = aes(x = Target, y = Prediction)) +
        geom_tile(aes(fill = values), colour = "white") +
        geom_text(aes(label = sprintf("%1.0f", values)), vjust = 1) +
        scale_fill_gradient(low = "azure1", high = "lightblue4") +
        theme_bw() + theme(legend.position = "none")
    
    print(plot)
    return(plot)
}

plot_prevalence <- function(lr_result)
{
    prevalence_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(prevalence_df) <- c("Cut_Off", "Prevalence")

    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        prevalence <- get_prevalence(lr_result, cut_off = i)
        prevalence_df[nrow(prevalence_df) + 1,] <- c(i, prevalence)
    }
    
    plot <- ggplot(data = prevalence_df, aes(x = Cut_Off, y = Prevalence, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(prevalence_df$Cut_Off),
                           breaks = prevalence_df$Cut_Off)
    
    print(plot)
    return(list("df" = prevalence_df,
                "plot" = plot))
}

plot_accuracy <- function(lr_result)
{
    accuracy_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(accuracy_df) <- c("Cut_Off", "Accuracy")
    
    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        accuracy <- get_accuracy(lr_result, cut_off = i)
        accuracy_df[nrow(accuracy_df) + 1,] <- c(i, accuracy)
    }
    
    plot <- ggplot(data = accuracy_df, aes(x = Cut_Off, y = Accuracy, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(accuracy_df$Cut_Off),
                           breaks = accuracy_df$Cut_Off)
    
    print(plot)
    return(list("df" = accuracy_df,
                "plot" = plot))
}

plot_sensitivity <- function(lr_result)
{
    sensitivity_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(sensitivity_df) <- c("Cut_Off", "Sensitivity")

    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        sensitivity <- get_sensitivity(lr_result, cut_off = i)
        sensitivity_df[nrow(sensitivity_df) + 1,] <- c(i, sensitivity)
    }
    plot <- ggplot(data = sensitivity_df, aes(x = Cut_Off, y = Sensitivity, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(sensitivity_df$Cut_Off),
                           breaks = sensitivity_df$Cut_Off)
    
    print(plot)
    return(list("df" = sensitivity_df,
                "plot" = plot))
}

plot_specificity <- function(lr_result)
{
    specificity_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(specificity_df) <- c("Cut_Off", "Specificity")
    
    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        specificity <- get_specificity(lr_result, cut_off = i)
        specificity_df[nrow(specificity_df) + 1,] <- c(i, specificity)
    }
    plot <- ggplot(data = specificity_df, aes(x = Cut_Off, y = Specificity, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(specificity_df$Cut_Off),
                           breaks = specificity_df$Cut_Off)
    
    print(plot)
    return(list("df" = specificity_df,
                "plot" = plot))
}

plot_false_discovery_ratio <- function(lr_result)
{
    fdr_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(fdr_df) <- c("Cut_Off", "False_Discovery_Ratio")

    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        fdr <- get_false_discovery_ratio(lr_result, cut_off = i)
        fdr_df[nrow(fdr_df) + 1,] <- c(i, fdr)
    }
    plot <- ggplot(data = fdr_df, aes(x = Cut_Off, y = False_Discovery_Ratio, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(fdr_df$Cut_Off),
                           breaks = fdr_df$Cut_Off)
    
    print(plot)
    return(list("df" = fdr_df,
                "plot" = plot))
}

plot_diagnostic_odds_ratio <- function(lr_result)
{
    dor_df <- data.frame(matrix(ncol = 2, nrow = 0))
    colnames(dor_df) <- c("Cut_Off", "Diagnostic_Odds_Ratio")

    for(i in seq(from = 0.1, to = 0.9, by = 0.1))
    {
        dor <- get_diagnostic_odds_ratio(lr_result, cut_off = i)
        dor_df[nrow(dor_df) + 1,] <- c(i, dor)
    }
    plot <- ggplot(data = dor_df, aes(x = Cut_Off, y = Diagnostic_Odds_Ratio, fill = Cut_Off)) + 
        geom_bar(stat = "identity") +
        scale_x_continuous("Cut Off Values",
                           labels = as.character(dor_df$Cut_Off),
                           breaks = dor_df$Cut_Off)
    
    print(plot)
    return(list("df" = dor_df,
                "plot" = plot))
}

print_summary <- function(lr_result)
{
    if(class(lr_result) == "logistic_regression")
    {
        cat("Initial values used for beta:", "\n")
        print(lr_result$initial_beta)

        cat("\n", "Estimated coefficients found:", "\n", sep = "")
        print(lr_result$beta_estimate)
        
        cm <- get_confusion_matrix(lr_result)
        confusion_matrix <- matrix(c(cm$tp, cm$fp, cm$fn, cm$tn), nrow = 2, ncol = 2)
        colnames(confusion_matrix) <- c("Predicted Positive", "Predicted Negative")
        rownames(confusion_matrix) <- c("Actual Positive", "Actual Negative")
        cat("\n", "Confusion Matrix with cut off value = 0.5:", "\n", sep = "")
        print(confusion_matrix)
        
        cat("\n", "Prevalence: ", get_prevalence(lr_result), "\n", sep = "")
        cat("Accuracy:", get_accuracy(lr_result), "\n")
        cat("Sensitivity:", get_sensitivity(lr_result), "\n")
        cat("Specificity:", get_specificity(lr_result), "\n")
        cat("False Discovery Ratio:", get_false_discovery_ratio(lr_result), "\n")
        cat("Diagnostic Odds Ratio:", get_diagnostic_odds_ratio(lr_result), "\n\n")
        
        get_beta_confidence_intervals(lr_result$response,
                                      lr_result$predictors,
                                      alpha = 0.05)
    }
}

# Variables for testing

testing <- function()
{
    size <- 1000
    set.seed(1)
    Intercept <- rep(1, size)
    gender <- sample(c(0, 1), size = size, replace = TRUE)
    age <- round(runif(size, 18, 80))
    
    predictors <- cbind(Intercept, gender, age)
    
    xb <- -9 + 3.5*gender + 0.2*age
    p <- 1/(1 + exp(-xb))
    response <- rbinom(n = size, size = 1, prob = p)
    
    # Using the glm function
    mod <- glm(response ~ gender + age, family = "binomial")
    prediction_glm <- predict(mod, as.data.frame(predictors), type = "response")
    
    
    # Our Logistic Regression
    lr_result <- get_beta_estimate(response = response, predictors = predictors)
    
    #print_summary(lr_result)
    #plot <- plot_confusion_matrix(lr_result)
    
    #prevalence <- plot_prevalence(lr_result)
    #prevalence
    
    #accuracy <- plot_accuracy(lr_result)
    #accuracy
    
    #sensitivity <- plot_sensitivity(lr_result)
    #sensitivity
    
    #specificity <- plot_specificity(lr_result)
    #specificity
    
    #dor <- plot_diagnostic_odds_ratio(lr_result)
    #dor
    
    fdr <- plot_false_discovery_ratio(lr_result)
    fdr
}
